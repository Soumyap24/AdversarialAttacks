# -*- coding: utf-8 -*-
"""grayscaleATTACKbas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BfbQOrFn8Is63mhfDMPKsb6vOnSn-Da3
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Load and preprocess the data
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train[:10000].reshape(-1, 28, 28, 1).astype('float32') / 255.0  # Use a subset for faster training
y_train = to_categorical(y_train[:10000], 10)
x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0
y_test = to_categorical(y_test, 10)

# Define the CNN model
model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=200)  # Reduce epochs for faster training

# Function to add noise to specific pixels
def perturb_pixels(image, pixel_indices, noise_level):  # Further increased noise level
    perturbed_image = np.copy(image)
    for idx in pixel_indices:
        x, y = idx
        perturbed_image[x, y] += noise_level #* np.random.normal()


    perturbed_image = np.clip(perturbed_image, 0.0, 1.0)
    return perturbed_image

# Select a single image from the test set
single_image = x_test[18]
single_image_label = y_test[18]
single_image_expanded = np.expand_dims(single_image, axis=0)

# Original prediction
original_prediction = np.argmax(model.predict(single_image_expanded))
print(f'Original prediction: {original_prediction}')

# Visualize original image
plt.figure(figsize=(10, 10))
plt.subplot(3, 3, 1)
plt.title('Original Image')
plt.imshow(single_image.squeeze(), cmap='gray')
plt.axis('off')



perturbed_images = []

def fun(image, pixels, noise_level):

    perturbed_image = perturb_pixels(single_image, pixels,noise_level)
    perturbed_images.append(perturbed_image)
    perturbed_image_expanded = np.expand_dims(perturbed_image, axis=(0))
    prediction = np.argmax(model.predict(perturbed_image_expanded))
    prob=model.predict(perturbed_image_expanded)
    print(f'Perturbed image prediction .........{prediction}')
    max_value = np.max(prob)

    # plt.title(f'Perturbed Image { 1}\nPrediction: {prediction}')
    plt.imshow(perturbed_image.squeeze(), cmap='gray')
    plt.axis('off')
    # plt.show()


    if prob[0][3]<max_value:
       print("missclassify")

    return prob[0][3]*100

# BAS algorithm
def bas(image, num_pixels_to_perturb, noise_level, n):
    # Parameter setup
    # Parameter setup
    d0 = 0.1
    d1 = 5
    d = d1
    eta_d = 0.99  # Slow reduction of the antenna distance

    l0 = 0.1
    l1 = 0.5
    l = l1
    eta_l = 0.98  # Slow reduction of the random walk

    step = 5
    eta_step = 0.98  # Slow reduction of the step size

    # x0 = [(np.random.randint(0, 28), np.random.randint(0, 28)) for _ in range(num_pixels_to_perturb)]
    # x0 =[(0, 11), (4, 11), (17, 12), (5, 19), (0, 0)]
    # x0= [(16, 12), (16, 2), (2, 5), (0, 14), (1, 2)]
    #x0=[(16, 1), (16, 16), (11, 8), (6, 22), (2, 18)]
    x0=[(5, 22), (12, 17), (14, 0), (0, 13), (6, 20)]







    x = np.array(x0)
    xbest = x0
    fbest = fun(image, xbest, noise_level)
    fbest_store = [fbest]
    x_store = np.hstack([[0], x[:, 0], x[:, 1], [fbest]])
    print(f"0: xbest = {xbest}, fbest = {fbest}")
 # Iteration
    for i in range(1, n + 1):
        # dir = np.random.randn(num_pixels_to_perturb, 2)
        # dir = dir / (np.linalg.norm(dir, axis=1, keepdims=True) + np.finfo(float).eps)
        # xleft = np.clip(x + dir * d, 0, 27).astype(int)
        # print(xleft)
        # fleft = fun(image, xleft, noise_level)
        # xright = np.clip(x - dir * d, 0, 27).astype(int)
        # fright = fun(image, xright, noise_level)
        # w = l * np.random.randn(num_pixels_to_perturb, 2)
        # x = np.clip(x - step * dir * np.sign(fleft - fright) + w, 0, 27).astype(int)
        # f = fun(image, x, noise_level)

       dir = np.random.randn(num_pixels_to_perturb, 2)
       dir = dir / (np.linalg.norm(dir, axis=1, keepdims=True) + np.finfo(float).eps)
       xleft = np.clip(x + dir * d, 0, 27).astype(int)
       fleft = fun(image, [tuple(coord) for coord in xleft], noise_level)
       xright = np.clip(x - dir * d, 0, 27).astype(int)
       fright = fun(image, [tuple(coord) for coord in xright], noise_level)
       w = l * np.random.randn(num_pixels_to_perturb, 2)
       x = np.clip(x - step * dir * np.sign(fleft - fright) + w, 0, 27).astype(int)
       print(x[0])
       f = fun(image, [tuple(coord) for coord in x], noise_level)

       if f < fbest:
            xbest = x
            fbest = f

      #  x_store = np.hstack(x_store, [tuple(coord) for coord in x], [f])
      #  fbest_store.append(fbest)
       print(f"{i}: fbest = {fbest}")

       d = d * eta_d + d0
       l = l * eta_l + l0
       step = step * eta_step

    # # Data visualization
    # plt.figure(1)
    # plt.plot(x_store[1, :], x_store[2, :], 'r-.')
    # plt.axis('equal')
    # xlim0 = [min(x_store[1, :]), max(x_store[1, :])]
    # ylim0 = [min(x_store[2, :]), max(x_store[2, :])]
    # x, y = np.meshgrid(
    #     np.linspace(xlim0[0], xlim0[1], 50),
    #     np.linspace(ylim0[0], ylim0[1], 50)
    # )
    # f_val = np.vectorize(lambda p: fun(image, [p], noise_level))(np.vstack((x.ravel(), y.ravel())).T).reshape(x.shape)
    # plt.contour(x, y, f_val, 50)
    # plt.colorbar()
    # plt.plot(x_store[1, -1], x_store[2, -1], 'b*')
    # plt.plot(xbest[:, 0], xbest[:, 1], 'r*')
    # plt.show()

    # plt.figure(3)
    # plt.plot(x_store[0, :], x_store[3, :], 'r-o')
    # plt.plot(x_store[0, :], fbest_store, 'b-.')
    # plt.xlabel('Iteration')
    # plt.ylabel('Minimum value')
    # plt.show()
          # Data visualization
    # plt.figure(1)
    # for iter_num, coords, value in x_store:
    #     x_coords, y_coords = zip(*coords)
    #     plt.scatter(x_coords, y_coords, label=f"Iter {iter_num} - fbest: {value:.2f}")

    # plt.legend()
    # plt.xlim(0, 27)
    # plt.ylim(0, 27)
    # plt.xlabel('X Coordinate')
    # plt.ylabel('Y Coordinate')
    # plt.title('Pixel Perturbations over Iterations')
    # plt.show()

    # plt.figure(3)
    # iterations, _, fbest_values = zip(*x_store)
    # plt.plot(iterations, fbest_store, 'b-.')
    # plt.xlabel('Iteration')
    # plt.ylabel('Minimum value')
    # plt.title('Best Objective Function Value over Iterations')
    # plt.show()
    print(f"{i}: x0 = {x0}")
    print(f"{i}: xbest = {xbest}")

bas(single_image,5,0.5,1)